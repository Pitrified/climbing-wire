{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from climbing_wire.homography.homography import compute_homography\n",
    "from climbing_wire.homography.homography import perspective_transform\n",
    "from climbing_wire.landmark.compute import PoseImg\n",
    "from climbing_wire.landmark.compute import compute_landmarks\n",
    "from climbing_wire.landmark.drawing import draw_landmarks\n",
    "from climbing_wire.landmark.landmark_list import LandmarkListImg\n",
    "from climbing_wire.utils.cv import cv_imshow\n",
    "from climbing_wire.utils.cv import show_frame\n",
    "from climbing_wire.utils.cv import show_warp\n",
    "from climbing_wire.utils.data import get_package_fol\n",
    "from climbing_wire.utils.mediapipe import JOINT_NAMES\n",
    "from climbing_wire.utils.mediapipe import get_default_pose_connections\n",
    "from climbing_wire.video.frame import Frame\n",
    "from climbing_wire.video.load import iterate_video_frames\n",
    "from climbing_wire.video.load import iterate_video_frames_with_timestamp\n",
    "from climbing_wire.video.load import list_video_frames_with_timestamp\n",
    "from climbing_wire.video.load import pairwise_video_frames\n",
    "from loguru import logger as lg\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.interpolate import splrep, BSpline\n",
    "from typing import Any\n",
    "from typing import List, Tuple, cast\n",
    "import cv2 as cv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import mediapipe.python.solutions.drawing_styles as mp_drawing_styles\n",
    "import mediapipe.python.solutions.drawing_utils as mp_drawing\n",
    "import mediapipe.python.solutions.pose as mp_pose\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataclasses import dataclass\n",
    "\n",
    "\n",
    "# @dataclass\n",
    "# class Frame:\n",
    "#     frame: np.ndarray\n",
    "#     usec: int\n",
    "#     idx: int\n",
    "\n",
    "#     def __str__(self) -> str:\n",
    "#         return f\"Frame(idx={self.idx}, usec={self.usec})\"\n",
    "\n",
    "#     # dataclasses have repr already test that\n",
    "#     # def __repr__(self) -> str:\n",
    "#     #     return str(self)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_fol = Path(\"/mnt/c/Users/nobilip/Videos/dataset/rock\")\n",
    "in_fol = Path(\"~/data/rock\").expanduser()\n",
    "\n",
    "# person_fn = \"PXL_20230401_135540281.TS.mp4\"\n",
    "person_fn = \"andre_01.mp4\"\n",
    "empty_fn = \"empty_01.mp4\"\n",
    "\n",
    "# in_fn = \"nonaka_miho_01.mp4\"\n",
    "\n",
    "person_vid_path = in_fol / person_fn\n",
    "empty_vid_path = in_fol / empty_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_every_nth_frame = 15\n",
    "max_num_frames = 30\n",
    "fps = 30\n",
    "print(\n",
    "    f\"will keep a frame every {keep_every_nth_frame * fps} milliseconds,\"\n",
    "    f\" will load {fps * keep_every_nth_frame * max_num_frames} milliseconds\"\n",
    ")\n",
    "\n",
    "# frame_num = 0\n",
    "# for frame, usec in iterate_video_frames_with_timestamp(\n",
    "#     person_vid_path,\n",
    "#     keep_every_nth_frame=keep_every_nth_frame,\n",
    "# ):\n",
    "#     # print(usec)\n",
    "#     f = Frame(frame=frame, usec=usec, idx=frame_num)\n",
    "#     per_frames.append(f)\n",
    "#     frame_num += 1\n",
    "#     if frame_num >= max_num_frames:\n",
    "#         break\n",
    "\n",
    "# per_frames: list[Frame] = []\n",
    "per_frames = list_video_frames_with_timestamp(\n",
    "    person_vid_path,\n",
    "    keep_every_nth_frame=keep_every_nth_frame,\n",
    "    max_frame_count=max_num_frames,\n",
    ")\n",
    "\n",
    "print(f\"{len(per_frames)} frames\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_every_nth_frame = 3\n",
    "# max_num_frames = 15\n",
    "max_num_frames = 1500\n",
    "fps = 30\n",
    "print(\n",
    "    f\"will keep a frame every {keep_every_nth_frame * fps} milliseconds,\"\n",
    "    f\" will load {fps * keep_every_nth_frame * max_num_frames} milliseconds\"\n",
    ")\n",
    "\n",
    "# empty_frames: list[Frame] = []\n",
    "# frame_num = 0\n",
    "# for frame, usec in iterate_video_frames_with_timestamp(\n",
    "#     empty_vid_path,\n",
    "#     keep_every_nth_frame=keep_every_nth_frame,\n",
    "# ):\n",
    "#     # print(usec)\n",
    "#     f = Frame(frame=frame, usec=usec, idx=frame_num)\n",
    "#     empty_frames.append(f)\n",
    "#     frame_num += 1\n",
    "#     if frame_num >= max_num_frames:\n",
    "#         break\n",
    "\n",
    "empty_frames = list_video_frames_with_timestamp(\n",
    "    empty_vid_path,\n",
    "    keep_every_nth_frame=keep_every_nth_frame,\n",
    "    max_frame_count=max_num_frames,\n",
    ")\n",
    "\n",
    "print(len(empty_frames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_frame(\n",
    "#     frame: Frame,\n",
    "#     ax: plt.Axes | None = None,\n",
    "# ):\n",
    "#     \"\"\"A wrapper around cv_imshow that adds a title and removes the ticks.\n",
    "#     #\n",
    "#     TODO: let cv_imshow return the ax it creates, so we can chain it with this function.\n",
    "#     \"\"\"\n",
    "#     if ax is None:\n",
    "#         fig, ax = plt.subplots(1, 1)\n",
    "#     cv_imshow(frame.frame, ax=ax)\n",
    "#     ax.set_title(f\"{frame.idx} @ {frame.usec}\")\n",
    "#     ax_params = dict(\n",
    "#         which=\"both\",\n",
    "#         # bottom=False,\n",
    "#         # top=False,\n",
    "#         # left=False,\n",
    "#         # right=False,\n",
    "#         labelbottom=False,\n",
    "#         labeltop=False,\n",
    "#         labelleft=False,\n",
    "#         labelright=False,\n",
    "#     )\n",
    "#     ax.tick_params(**ax_params)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "# show_frame(per_frames[7], ax=ax[0])\n",
    "show_frame(per_frames[-2], ax=ax[0])\n",
    "# show_frame(empty_frames[11], ax=ax[1])\n",
    "show_frame(empty_frames[8], ax=ax[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_warp(f1: Frame, f2: Frame, M: np.ndarray) -> None:\n",
    "#     \"\"\"Draw the first image warped on the second.\n",
    "\n",
    "#     TODO: Let f1 be a Frame|np.ndarray, then extract as needed.\n",
    "#     \"\"\"\n",
    "#     f1img = f1.frame\n",
    "#     f2img = f2.frame\n",
    "\n",
    "#     corners = np.array(\n",
    "#         [\n",
    "#             [0, 0],\n",
    "#             [f1img.shape[1], 0],\n",
    "#             [f1img.shape[1], f1img.shape[0]],\n",
    "#             [0, f1img.shape[0]],\n",
    "#         ],\n",
    "#         dtype=np.float32,\n",
    "#     )\n",
    "#     corners_warp = perspective_transform(corners, M)\n",
    "#     f2_ann = cv.polylines(\n",
    "#         f2img.copy(), [np.int32(corners_warp)], True, 255, 3, cv.LINE_AA\n",
    "#     )\n",
    "#     # blend the person frame on the empty frame\n",
    "#     f1_warped = cv.warpPerspective(f1img, M, f1img.shape[:2][::-1])\n",
    "#     f_blend = cv.addWeighted(f1_warped, 0.5, f2_ann, 0.5, 0)\n",
    "\n",
    "#     fig, ax = plt.subplots(1, 1)\n",
    "#     ax_params = dict(\n",
    "#         which=\"both\",\n",
    "#         # bottom=False,\n",
    "#         # top=False,\n",
    "#         # left=False,\n",
    "#         # right=False,\n",
    "#         labelbottom=False,\n",
    "#         labeltop=False,\n",
    "#         labelleft=False,\n",
    "#         labelright=False,\n",
    "#     )\n",
    "#     ax.tick_params(**ax_params)\n",
    "#     ax.set_title(f\"{f1.idx} -> {f2.idx}\")\n",
    "#     cv_imshow(f_blend, ax=ax)\n",
    "\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 = per_frames[0]\n",
    "# f2 = empty_frames[0]\n",
    "\n",
    "f1 = per_frames[7]\n",
    "f2 = empty_frames[11]\n",
    "\n",
    "# f1 = per_frames[-1]\n",
    "# f2 = empty_frames[-1]\n",
    "\n",
    "\n",
    "def homography_distance(\n",
    "    f1: Frame,\n",
    "    f2: Frame,\n",
    "    do_plot: bool = False,\n",
    "    ax: plt.Axes | None = None,\n",
    ") -> float:\n",
    "    # lg.debug(f\"{f1.usec=} {f2.usec=}\")\n",
    "    # print(\".\", end=\"\", flush=True)\n",
    "\n",
    "    f1img = f1.frame\n",
    "    f2img = f2.frame\n",
    "\n",
    "    # shrink images to speed up computation\n",
    "    f1img = cv.resize(f1img, (0, 0), fx=0.5, fy=0.5)\n",
    "    f2img = cv.resize(f2img, (0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "    # compute homography might fail if there are not enough features\n",
    "    # so we just return a large number\n",
    "    try:\n",
    "        M = compute_homography(f1img, f2img)\n",
    "    except ValueError:\n",
    "        lg.debug(f\"failed homography for {f1} {f2}\")\n",
    "        # assume that one image is completely outside the other\n",
    "        # return (f1img.shape[0] + f1img.shape[1]) * 2\n",
    "        return ((f1img.shape[0] + f1img.shape[1]) * 2) ** 2\n",
    "\n",
    "    corners = np.array(\n",
    "        [\n",
    "            [0, 0],\n",
    "            [f1img.shape[1], 0],\n",
    "            [f1img.shape[1], f1img.shape[0]],\n",
    "            [0, f1img.shape[0]],\n",
    "        ],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "    corners_warp = perspective_transform(corners, M)\n",
    "    corners_delta = corners_warp - corners\n",
    "    # dist = np.linalg.norm(corners_delta, axis=1).mean()\n",
    "    dist = (corners_delta**2).mean()\n",
    "\n",
    "    # draw the first image warped on the second\n",
    "    # rather than doing this, turn homography_distance into a class\n",
    "    # maybe a single class with class methods?\n",
    "    if do_plot:\n",
    "        show_warp(\n",
    "            Frame(f1img, f1.usec, f1.idx),\n",
    "            Frame(f2img, f2.usec, f2.idx),\n",
    "            M,\n",
    "            ax=ax,\n",
    "            dist=dist,\n",
    "        )\n",
    "\n",
    "    return dist\n",
    "\n",
    "\n",
    "homography_distance(f1, f2, do_plot=True)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # draw the warped corners on the image\n",
    "# f2_ann = cv.polylines(\n",
    "#     f2.frame.copy(), [np.int32(corners_warp)], True, 255, 3, cv.LINE_AA\n",
    "# )\n",
    "# # blend the person frame on the empty frame\n",
    "# f1_warped = cv.warpPerspective(f1.frame, M, f1.frame.shape[:2][::-1])\n",
    "# f_blend = cv.addWeighted(f1_warped, 0.5, f2_ann, 0.5, 0)\n",
    "# cv_imshow(f_blend)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(per_frames), len(empty_frames)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute path with DTW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastdtw.fastdtw import fastdtw\n",
    "\n",
    "# from fastdtw.fastdtw import __dtw\n",
    "# from fastdtw.fastdtw import __fastdtw\n",
    "\n",
    "distance, path = fastdtw(\n",
    "    # distance, path = __fastdtw(\n",
    "    per_frames[:-2],\n",
    "    empty_frames[:],\n",
    "    10,\n",
    "    dist=homography_distance,\n",
    ")\n",
    "print(distance, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot([x[0] for x in path], [x[1] for x in path])\n",
    "plt.scatter([x[0] for x in path], [x[1] for x in path])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpolate with pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pathdf = pd.DataFrame(\n",
    "    path,\n",
    "    columns=[\"per_idx\", \"empty_idx\"],\n",
    ")\n",
    "pathdf[\"per_usec\"] = pathdf[\"per_idx\"].apply(lambda idx: per_frames[idx].usec)\n",
    "pathdf[\"empty_usec\"] = pathdf[\"empty_idx\"].apply(lambda idx: empty_frames[idx].usec)\n",
    "pathdf.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_empty_usec(\n",
    "    pathdf: pd.DataFrame,\n",
    "    new_per_usec: int,\n",
    ") -> int:\n",
    "    \"\"\"Linear interpolation of empty_usec given per_usec.\"\"\"\n",
    "    per_usec_before = pathdf[pathdf[\"per_usec\"] <= new_per_usec][\"per_usec\"].max()\n",
    "    per_usec_after = pathdf[pathdf[\"per_usec\"] > new_per_usec][\"per_usec\"].min()\n",
    "    print(per_usec_before, per_usec_after)\n",
    "\n",
    "    em_usec_before, em_usec_after = pathdf[\n",
    "        pathdf[\"per_usec\"].isin([per_usec_before, per_usec_after])\n",
    "    ][\"empty_usec\"].values\n",
    "    print(em_usec_before, em_usec_after)\n",
    "\n",
    "    # interpolate the empty_usec value\n",
    "    em_usec_new = em_usec_before + (new_per_usec - per_usec_before) * (\n",
    "        em_usec_after - em_usec_before\n",
    "    ) / (per_usec_after - per_usec_before)\n",
    "    print(em_usec_new)\n",
    "    return int(em_usec_new)\n",
    "\n",
    "\n",
    "new_per_usec = 1_000_000\n",
    "interpolate_empty_usec(pathdf, new_per_usec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # show the path frame warps\n",
    "# for per_idx, empty_idx in path:\n",
    "#     f1 = per_frames[per_idx]\n",
    "#     f2 = empty_frames[empty_idx]\n",
    "#     homography_distance(f1, f2, do_plot=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpolate with scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to frame pairs\n",
    "path_frames: list[tuple[Frame, Frame]] = [\n",
    "    (per_frames[p[0]], empty_frames[p[1]]) for p in path\n",
    "]\n",
    "path_frames[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract idx\n",
    "per_idx_path = [f[0].idx for f in path_frames]\n",
    "empty_idx_path = [f[1].idx for f in path_frames]\n",
    "\n",
    "# extract usec\n",
    "per_usec_path = [f[0].usec for f in path_frames]\n",
    "empty_usec_path = [f[1].usec for f in path_frames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splrep_(per_usec_path, empty_usec_path, **kwargs) -> tuple[Any, Any, int]:\n",
    "    tck = cast(tuple[Any, Any, int], splrep(per_usec_path, empty_usec_path, **kwargs))\n",
    "    return tck\n",
    "\n",
    "\n",
    "tck = splrep_(per_usec_path, empty_usec_path)\n",
    "xnew = np.linspace(0, max(per_usec_path), 100)\n",
    "plt.scatter(per_usec_path, empty_usec_path)\n",
    "plt.plot(xnew, BSpline(*tck)(xnew))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_spline(tck, x):\n",
    "    \"\"\"Interpolate a spline at a given point.\"\"\"\n",
    "    return BSpline(*tck)([x])[0]\n",
    "\n",
    "\n",
    "requested_usec = 1000000\n",
    "interpolate_spline(tck, requested_usec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we load the whole empty video\n",
    "# TODO turn it into a coroutine so that we can change the target millisecond frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_every_nth_frame = 1\n",
    "max_num_frames = 1500\n",
    "fps = 30\n",
    "print(\n",
    "    f\"will keep a frame every {keep_every_nth_frame * fps} milliseconds,\"\n",
    "    f\" will load {fps * keep_every_nth_frame * max_num_frames} milliseconds\"\n",
    ")\n",
    "\n",
    "# empty_frames_all: list[Frame] = []\n",
    "# frame_num = 0\n",
    "# for frame, usec in iterate_video_frames_with_timestamp(\n",
    "#     empty_vid_path,\n",
    "#     keep_every_nth_frame=keep_every_nth_frame,\n",
    "# ):\n",
    "#     f = Frame(frame=frame, usec=usec, idx=frame_num)\n",
    "#     empty_frames_all.append(f)\n",
    "#     frame_num += 1\n",
    "#     if frame_num >= max_num_frames:\n",
    "#         break\n",
    "\n",
    "empty_frames_all = list_video_frames_with_timestamp(\n",
    "    empty_vid_path,\n",
    "    keep_every_nth_frame=keep_every_nth_frame,\n",
    "    max_frame_count=max_num_frames,\n",
    ")\n",
    "\n",
    "print(len(empty_frames_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the frame closest to a given usec\n",
    "\n",
    "\n",
    "def get_closest_frame(\n",
    "    frames: list[Frame],\n",
    "    usec: int,\n",
    ") -> Frame:\n",
    "    \"\"\"Get the frame closest to a given usec.\"\"\"\n",
    "    return min(frames, key=lambda f: abs(f.usec - usec))\n",
    "\n",
    "\n",
    "get_closest_frame(empty_frames_all, 1000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_landlist(\n",
    "    landlist: LandmarkListImg,\n",
    "    M: np.ndarray,\n",
    ") -> LandmarkListImg:\n",
    "    \"\"\"Warp a landmark list.\n",
    "\n",
    "    Note that this does not change the normalized landmarks.\n",
    "    \"\"\"\n",
    "    lli_warped = landlist.copy()\n",
    "    lli_warped.landmarks_img = perspective_transform(\n",
    "        lli_warped.landmarks_img.astype(np.float64), M\n",
    "    ).astype(int)\n",
    "    return lli_warped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the whole person video\n",
    "# find the closest frame to the empty frame by interpolation\n",
    "# find the wireframe of the person\n",
    "# compute the homography between the person and the empty frame\n",
    "# warp it to the empty frame\n",
    "# plot it on the empty frame\n",
    "# save the empty frame\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "cds = mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=8, circle_radius=2)\n",
    "lds = mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=8, circle_radius=8)\n",
    "\n",
    "pose_img_kwargs: dict[str, Any] = {}\n",
    "pose_img = PoseImg(**pose_img_kwargs)\n",
    "\n",
    "\n",
    "keep_every_nth_frame = 1\n",
    "max_num_frames = 500\n",
    "fps = 30\n",
    "print(\n",
    "    f\"will keep a frame every {keep_every_nth_frame * fps} milliseconds,\"\n",
    "    f\" will load {fps * keep_every_nth_frame * max_num_frames} milliseconds\"\n",
    ")\n",
    "\n",
    "frame_width = 1080\n",
    "frame_height = 1920\n",
    "print(\"Frame size \", (frame_width, frame_height))\n",
    "output = cv.VideoWriter(\n",
    "    \"output_video.mp4\",\n",
    "    cv.VideoWriter_fourcc(*\"mp4v\"),\n",
    "    30,\n",
    "    (int(frame_width), int(frame_height)),\n",
    ")\n",
    "\n",
    "pbar = tqdm(total=max_num_frames)\n",
    "\n",
    "frame_num = 0\n",
    "for frame, usec in iterate_video_frames_with_timestamp(\n",
    "    person_vid_path,\n",
    "    keep_every_nth_frame=keep_every_nth_frame,\n",
    "):\n",
    "    # print(usec)\n",
    "    per_frame = Frame(frame=frame, usec=usec, idx=frame_num)\n",
    "\n",
    "    # find the wireframe of the person\n",
    "    wireframe = pose_img(per_frame.frame)\n",
    "    if wireframe is None:\n",
    "        continue\n",
    "\n",
    "    # find the closest empty frame\n",
    "    closest_empty_frame = get_closest_frame(empty_frames_all, per_frame.usec)\n",
    "\n",
    "    # compute the homography between the person and the empty frame\n",
    "    try:\n",
    "        M = compute_homography(per_frame.frame, closest_empty_frame.frame)\n",
    "    except ValueError:\n",
    "        lg.debug(f\"Could not compute homography {per_frame} {closest_empty_frame}\")\n",
    "        continue\n",
    "\n",
    "    lli_warped = warp_landlist(wireframe, M)\n",
    "    ef_ann = closest_empty_frame.frame.copy()\n",
    "    draw_landmarks(\n",
    "        ef_ann,\n",
    "        lli_warped,\n",
    "        landmark_drawing_spec=lds,\n",
    "        connection_drawing_spec=cds,\n",
    "    )\n",
    "    # cv_imshow(ef_ann)\n",
    "    output.write(ef_ann)\n",
    "\n",
    "    pbar.update(1)\n",
    "\n",
    "    frame_num += 1\n",
    "    if frame_num >= max_num_frames:\n",
    "        break\n",
    "\n",
    "    # break\n",
    "\n",
    "pbar.close()\n",
    "# pose_img.close()\n",
    "output.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiments with warping a wireframe\n",
    "# cds = mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=8, circle_radius=2)\n",
    "# lds = mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=8, circle_radius=8)\n",
    "# lli_warped = warp_landlist(wireframe, M)\n",
    "# ef_ann = closest_empty_frame.frame.copy()\n",
    "# draw_landmarks(\n",
    "#     ef_ann,\n",
    "#     lli_warped,\n",
    "#     landmark_drawing_spec=lds,\n",
    "#     connection_drawing_spec=cds,\n",
    "# )\n",
    "# cv_imshow(ef_ann)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create video from frames using opencv\n",
    "# frame_width = 1080\n",
    "# frame_height = 1920\n",
    "# print(\"Frame size \", (frame_width, frame_height))\n",
    "# output = cv.VideoWriter(\n",
    "#     \"output_video.mp4\",\n",
    "#     cv.VideoWriter_fourcc(*\"mp4v\"),\n",
    "#     30,\n",
    "#     (int(frame_width), int(frame_height)),\n",
    "# )\n",
    "# output.write(annotated_frame)\n",
    "# output.release()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neat but we want a better test of DTW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a lot of frames\n",
    "\n",
    "keep_every_nth_frame = 5\n",
    "max_num_frames = 60\n",
    "fps = 30\n",
    "print(\n",
    "    f\"will keep a frame every {keep_every_nth_frame * fps} milliseconds,\"\n",
    "    f\" will load {fps * keep_every_nth_frame * max_num_frames} milliseconds\"\n",
    ")\n",
    "\n",
    "# many_frames: list[Frame] = []\n",
    "# frame_num = 0\n",
    "# for frame, usec in iterate_video_frames_with_timestamp(\n",
    "#     person_vid_path,\n",
    "#     keep_every_nth_frame=keep_every_nth_frame,\n",
    "# ):\n",
    "#     # print(usec)\n",
    "#     f = Frame(frame=frame, usec=usec, idx=frame_num)\n",
    "#     many_frames.append(f)\n",
    "#     frame_num += 1\n",
    "#     if frame_num >= max_num_frames:\n",
    "#         break\n",
    "\n",
    "many_frames = list_video_frames_with_timestamp(\n",
    "    person_vid_path,\n",
    "    keep_every_nth_frame=keep_every_nth_frame,\n",
    "    max_frame_count=max_num_frames,\n",
    ")\n",
    "print(f\"{len(many_frames)} frames\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid1_frames_idx = [\n",
    "    0,\n",
    "    4,\n",
    "    8,\n",
    "    14,\n",
    "    19,\n",
    "    23,\n",
    "    29,\n",
    "    31,\n",
    "    36,\n",
    "    39,\n",
    "    40,\n",
    "    41,\n",
    "    42,\n",
    "    43,\n",
    "    48,\n",
    "    55,\n",
    "    58,\n",
    "]\n",
    "\n",
    "vid2_frames_idx = [\n",
    "    2,\n",
    "    3,\n",
    "    7,\n",
    "    17,\n",
    "    19,\n",
    "    24,\n",
    "    28,\n",
    "    32,\n",
    "    37,\n",
    "    38,\n",
    "    45,\n",
    "    48,\n",
    "    58,\n",
    "]\n",
    "\n",
    "vid1_frames = [f for f in many_frames if f.idx in vid1_frames_idx]\n",
    "vid2_frames = [f for f in many_frames if f.idx in vid2_frames_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance, path = fastdtw(\n",
    "    vid1_frames,\n",
    "    vid2_frames,\n",
    "    10,\n",
    "    dist=homography_distance,\n",
    ")\n",
    "print(distance, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [p[0] for p in path]\n",
    "y = [p[1] for p in path]\n",
    "plt.scatter(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.scipy.org/doc/scipy/tutorial/interpolate/smoothing_splines.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tuple (t,c,k) containing the vector of knots,\n",
    "# the B-spline coefficients, and the degree of the spline.\n",
    "\n",
    "# set smoothing to 1\n",
    "tck_idx: tuple[Any, Any, int] = splrep(x, y, s=1)\n",
    "xnew = np.linspace(0, max(x), 100)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xnew, BSpline(*tck_idx)(xnew))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the matched frame idx\n",
    "# the match here should be 1:1\n",
    "path1idx = [vid1_frames[p[0]].idx for p in path]\n",
    "path2idx = [vid2_frames[p[1]].idx for p in path]\n",
    "xend = max(path1idx)\n",
    "\n",
    "tck_idx: tuple[Any, Any, int] = splrep(path1idx, path2idx, s=1)\n",
    "xnew = np.linspace(0, max(path1idx), 100)\n",
    "ynew = BSpline(*tck_idx)(xnew)\n",
    "plt.plot(xnew, ynew)\n",
    "\n",
    "plt.scatter(path1idx, path2idx)\n",
    "plt.plot([0, xend], [0, xend], color=\"red\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to frame pairs\n",
    "path_frames = [(vid1_frames[p[0]], vid2_frames[p[1]]) for p in path]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_frames[0][0].frame.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the whole distance matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a lot of frames\n",
    "\n",
    "keep_every_nth_frame = 5\n",
    "max_num_frames = 60\n",
    "fps = 30\n",
    "print(\n",
    "    f\"will keep a frame every {keep_every_nth_frame * fps} milliseconds,\"\n",
    "    f\" will load {fps * keep_every_nth_frame * max_num_frames} milliseconds\"\n",
    ")\n",
    "\n",
    "many_frames = list_video_frames_with_timestamp(\n",
    "    person_vid_path,\n",
    "    keep_every_nth_frame=keep_every_nth_frame,\n",
    "    max_frame_count=max_num_frames,\n",
    ")\n",
    "print(f\"{len(many_frames)} frames\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid1_frames_idx = [\n",
    "    0,\n",
    "    4,\n",
    "    8,\n",
    "    14,\n",
    "    19,\n",
    "    23,\n",
    "    29,\n",
    "    31,\n",
    "    36,\n",
    "    39,\n",
    "    40,\n",
    "    41,\n",
    "    42,\n",
    "    43,\n",
    "    48,\n",
    "    55,\n",
    "    58,\n",
    "]\n",
    "\n",
    "vid2_frames_idx = [\n",
    "    2,\n",
    "    4,\n",
    "    7,\n",
    "    17,\n",
    "    19,\n",
    "    24,\n",
    "    28,\n",
    "    32,\n",
    "    37,\n",
    "    38,\n",
    "    45,\n",
    "    48,\n",
    "    58,\n",
    "]\n",
    "\n",
    "vid1_frames = [f for f in many_frames if f.idx in vid1_frames_idx]\n",
    "vid2_frames = [f for f in many_frames if f.idx in vid2_frames_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the two videos\n",
    "vid1_frames = per_frames[:24:2]\n",
    "vid2_frames = empty_frames[:40:2]\n",
    "vid1_frames_idx = [f.idx for f in vid1_frames]\n",
    "vid2_frames_idx = [f.idx for f in vid2_frames]\n",
    "len(vid1_frames), len(vid2_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = np.zeros((len(vid1_frames), len(vid2_frames)))\n",
    "fig, axes = plt.subplots(len(vid1_frames), len(vid2_frames), figsize=(34, 24))\n",
    "for i in range(len(vid1_frames)):\n",
    "    for j in range(len(vid2_frames)):\n",
    "        ax = axes[i][j]\n",
    "        dist[i, j] = homography_distance(\n",
    "            vid1_frames[i],\n",
    "            vid2_frames[j],\n",
    "            do_plot=True,\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.imshow(dist)\n",
    "ax.set_xticks(np.arange(len(vid2_frames)))\n",
    "ax.set_yticks(np.arange(len(vid1_frames)))\n",
    "ax.set_xticklabels(vid2_frames_idx)\n",
    "ax.set_yticklabels(vid1_frames_idx)\n",
    "\n",
    "plt.show()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climbing-wire-IpulR3Hj-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
